{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UMA1_eZKxb0_"
   },
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "from azureml.core import Experiment\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: C:\\Users\\makayser\\Desktop\\git\\mxk_retinanet\\notebook\\aml_config\\config.json\n",
      "mak-ml\twesteurope\tmakshared\twesteurope\n",
      "found compute target. just use it. gpucluster\n",
      "AzureBlob makml9496683038 azureml-blobstore-43aa3424-3674-489b-808b-1e49daacf13c\n"
     ]
    }
   ],
   "source": [
    "# load workspace configuration from the config.json file in the current folder.\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.location, ws.resource_group, ws.location, sep = '\\t')\n",
    "experiment_name = 'mxk-train'\n",
    "script_folder = './'\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "\n",
    "# choose a name for your cluster\n",
    "compute_name = \"gpucluster\"\n",
    "compute_min_nodes = 0\n",
    "compute_max_nodes = 4\n",
    "vm_size = \"STANDARD_NC6\"\n",
    "\n",
    "compute_target = ws.compute_targets[compute_name]\n",
    "if compute_target and type(compute_target) is AmlCompute:\n",
    "    print('found compute target. just use it. ' + compute_name)\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "print(ds.datastore_type, ds.account_name, ds.container_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ./bin\\__init__.py\n",
      "Uploading ./bin\\__pycache__\\__init__.cpython-36.pyc\n",
      "Uploading ./bin\\__pycache__\\train.cpython-36.pyc\n",
      "Uploading ./bin\\convert_model.py\n",
      "Uploading ./bin\\debug.py\n",
      "Uploading ./bin\\evaluate.py\n",
      "Uploaded ./bin\\evaluate.py, 1 files out of an estimated total of 6\n",
      "Uploaded ./bin\\debug.py, 2 files out of an estimated total of 6\n",
      "Uploaded ./bin\\__pycache__\\__init__.cpython-36.pyc, 3 files out of an estimated total of 6\n",
      "Uploaded ./bin\\convert_model.py, 4 files out of an estimated total of 6\n",
      "Uploaded ./bin\\__init__.py, 5 files out of an estimated total of 6\n",
      "Uploaded ./bin\\__pycache__\\train.cpython-36.pyc, 6 files out of an estimated total of 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_912b6e41e21b484084a14416f983d2ac"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ds.upload(src_dir='./bin', target_path='mxk-train', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v7gwRHFSDwHI"
   },
   "source": [
    "## Deploy Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    '--data-dir': ds.path('mxk').as_mount(),\n",
    "    '--epochs':1, \n",
    "    '--steps':2300,\n",
    "    '--fl-gamma':1.5,\n",
    "    '--fl-alpha':0.25,\n",
    "    '--weights': 'model/resnet50_coco_best_v2.1.0.h5',\n",
    "    '--backbone' : 'resnet50',\n",
    "    '--annotations':'train_set_v2_retina.csv',\n",
    "    '--classes':'classes.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'--data-dir': $AZUREML_DATAREFERENCE_8ab86004993e4bef9a669d5ce9e0959c,\n",
       " '--epochs': 1,\n",
       " '--steps': 2300,\n",
       " '--fl-gamma': 1.5,\n",
       " '--fl-alpha': 0.25,\n",
       " '--weights': 'model/resnet50_coco_best_v2.1.0.h5',\n",
       " '--backbone': 'resnet50',\n",
       " '--annotations': 'train_set_v2_retina.csv',\n",
       " '--classes': 'classes.csv'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Conda environment specification. The dependencies defined in this file will\r\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\r\n",
      "\n",
      "# Details about the Conda environment file format:\r\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\r\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\r\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\r\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "    # Required packages for AzureML execution, history, and data preparation.\r\n",
      "  - azureml-defaults\n",
      "  - opencv-python-headless\n",
      "- opencv=3.4.2\n",
      "- tensorflow-gpu\n",
      "- h5py\n",
      "- mesa-libgl-cos6-x86_64\n",
      "- pillow\n",
      "- six\n",
      "- progressbar2\n",
      "- keras\n",
      "channels:\n",
      "- conda-forge\n",
      "- anaconda\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_GPU_IMAGE\n",
    "\n",
    "cd = CondaDependencies()\n",
    "for ch in ['conda-forge','anaconda']:\n",
    "    cd.add_channel(ch)\n",
    "for pkg in ['opencv=3.4.2', 'tensorflow-gpu','h5py','mesa-libgl-cos6-x86_64', 'pillow', 'six', 'progressbar2',\n",
    "            'keras']:\n",
    "    cd.add_conda_package(pkg)\n",
    "for pkg in ['opencv-python-headless']:\n",
    "    cd.add_pip_package(pkg)\n",
    "print(cd.serialize_to_string())\n",
    "\n",
    "rc = RunConfiguration()\n",
    "rc.environment.python.conda_dependencies = cd\n",
    "rc.environment.docker.enabled = True\n",
    "rc.environment.docker.gpu_support = True\n",
    "rc.environment.docker.base_image = azureml.core.runconfig.DEFAULT_GPU_IMAGE\n",
    "\n",
    "from azureml.train.estimator import Estimator\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,\n",
    "               entry_script='train.py',                \n",
    "                environment_definition=rc.environment\n",
    "               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import RandomParameterSampling\n",
    "param_sampling = RandomParameterSampling( {\n",
    "        \"--lr\": uniform(1e-6, 1e-04),\n",
    "        \"--fl-gamma\": choice(0.75, 1, 1.25, 1.5, 1.75, 2, 2.25),\n",
    "        \"--fl-alpha\": choice(0.25, 0.5, 0.75, 1),\n",
    "        \"--neg-overlap\": choice (0.4, 0.5, 0.6),\n",
    "        \"--pos-overlap\": choice (0.5, 0.6, 0.7),\n",
    "        \"--fpn-layers\": choice (4, 5)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slack: slack allowed with respect to the best performing training run\n",
    "from azureml.train.hyperdrive import BanditPolicy\n",
    "early_termination_policy = BanditPolicy(slack_factor = 0.25, evaluation_interval=1, delay_evaluation=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_total_runs=30,\n",
    "max_concurrent_runs=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.run import Run\n",
    "run_logger = Run.get_context()\n",
    "run_logger.log(\"EAD_Score\", float(EAD_Score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import HyperDriveRunConfig\n",
    "hyperdrive_run_config = HyperDriveRunConfig(estimator=est,\n",
    "                          hyperparameter_sampling=param_sampling, \n",
    "                          policy=early_termination_policy,\n",
    "                          primary_metric_name=\"EAD_Score\", \n",
    "                          primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                          max_total_runs=max_total_runs,\n",
    "                          max_concurrent_runs=max_concurrent_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.submit(config=hyperdrive_run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.submit(est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2cd8036b65745ac955d430518b0c68e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>mxk-train</td><td>mxk-train_1552173280_6ff3a97a</td><td>azureml.scriptrun</td><td>Queued</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/50324bce-875f-4a7b-9d3c-0e33679f5d72/resourceGroups/makshared/providers/Microsoft.MachineLearningServices/workspaces/mak-ml/experiments/mxk-train/runs/mxk-train_1552173280_6ff3a97a\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: mxk-train,\n",
       "Id: mxk-train_1552173280_6ff3a97a,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Queued)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: mxk-train_1552173280_6ff3a97a\n",
      "\n",
      "Streaming azureml-logs/60_control_log.txt\n",
      "=========================================\n",
      "\n",
      "Streaming log file azureml-logs/60_control_log.txt\n",
      "\n",
      "Streaming azureml-logs/80_driver_log.txt\n",
      "========================================\n",
      "\n",
      "Using TensorFlow backend.\n",
      "2019-03-09 23:21:24.107271: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "Creating model, this may take a second...\n",
      "/azureml-envs/azureml_8401288191f71d56c0066a35ea6de0f8/lib/python3.6/site-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer classification_submodel due to mismatch in shape ((3, 3, 256, 63) vs (720, 256, 3, 3)).\n",
      "  weight_values[i].shape))\n",
      "/azureml-envs/azureml_8401288191f71d56c0066a35ea6de0f8/lib/python3.6/site-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer classification_submodel due to mismatch in shape ((63,) vs (720,)).\n",
      "  weight_values[i].shape))\n",
      "Epoch 1/1\n",
      "\n",
      "   1/2300 [..............................] - ETA: 8:29:36 - loss: 3.6002 - regression_loss: 2.4120 - classification_loss: 1.1881\n",
      "   2/2300 [..............................] - ETA: 6:36:31 - loss: 3.6698 - regression_loss: 2.4694 - classification_loss: 1.2004\n",
      "   3/2300 [..............................] - ETA: 6:27:30 - loss: 3.5641 - regression_loss: 2.3576 - classification_loss: 1.2065\n",
      "   4/2300 [..............................] - ETA: 6:05:38 - loss: 3.6175 - regression_loss: 2.4008 - classification_loss: 1.2167\n",
      "   5/2300 [..............................] - ETA: 5:47:52 - loss: 3.6034 - regression_loss: 2.3834 - classification_loss: 1.2199\n",
      "   6/2300 [..............................] - ETA: 5:34:47 - loss: 3.5434 - regression_loss: 2.2845 - classification_loss: 1.2589\n",
      "   7/2300 [..............................] - ETA: 5:21:57 - loss: 3.4910 - regression_loss: 2.2315 - classification_loss: 1.2596\n",
      "   8/2300 [..............................] - ETA: 5:12:01 - loss: 3.5392 - regression_loss: 2.2855 - classification_loss: 1.2537\n",
      "   9/2300 [..............................] - ETA: 5:03:52 - loss: 3.5825 - regression_loss: 2.3295 - classification_loss: 1.2530\n",
      "  10/2300 [..............................] - ETA: 4:58:39 - loss: 3.5739 - regression_loss: 2.3245 - classification_loss: 1.2494\n",
      "  11/2300 [..............................] - ETA: 4:53:37 - loss: 3.5695 - regression_loss: 2.3200 - classification_loss: 1.2495\n",
      "  12/2300 [..............................] - ETA: 4:48:53 - loss: 3.6281 - regression_loss: 2.3813 - classification_loss: 1.2468\n",
      "  13/2300 [..............................] - ETA: 4:45:15 - loss: 3.6406 - regression_loss: 2.3842 - classification_loss: 1.2564\n",
      "  14/2300 [..............................] - ETA: 4:41:40 - loss: 3.6708 - regression_loss: 2.4133 - classification_loss: 1.2575\n",
      "  15/2300 [..............................] - ETA: 4:39:07 - loss: 3.5765 - regression_loss: 2.3080 - classification_loss: 1.2684\n",
      "  16/2300 [..............................] - ETA: 4:38:49 - loss: 3.5573 - regression_loss: 2.2932 - classification_loss: 1.2641\n",
      "  17/2300 [..............................] - ETA: 4:36:53 - loss: 3.5297 - regression_loss: 2.2697 - classification_loss: 1.2599\n",
      "  18/2300 [..............................] - ETA: 4:35:51 - loss: 3.5390 - regression_loss: 2.2743 - classification_loss: 1.2648\n",
      "  19/2300 [..............................] - ETA: 4:34:24 - loss: 3.5482 - regression_loss: 2.2825 - classification_loss: 1.2657\n",
      "  20/2300 [..............................] - ETA: 4:32:49 - loss: 3.5614 - regression_loss: 2.2970 - classification_loss: 1.2644\n",
      "  21/2300 [..............................] - ETA: 4:34:56 - loss: 3.5582 - regression_loss: 2.2935 - classification_loss: 1.2647\n",
      "  22/2300 [..............................] - ETA: 4:33:24 - loss: 3.5464 - regression_loss: 2.2822 - classification_loss: 1.2643\n",
      "  23/2300 [..............................] - ETA: 4:33:05 - loss: 3.5003 - regression_loss: 2.2310 - classification_loss: 1.2693\n",
      "  24/2300 [..............................] - ETA: 4:31:32 - loss: 3.4926 - regression_loss: 2.2251 - classification_loss: 1.2675\n",
      "  25/2300 [..............................] - ETA: 4:30:35 - loss: 3.5101 - regression_loss: 2.2384 - classification_loss: 1.2717\n",
      "  26/2300 [..............................] - ETA: 4:32:15 - loss: 3.4869 - regression_loss: 2.2110 - classification_loss: 1.2759\n",
      "  27/2300 [..............................] - ETA: 4:31:04 - loss: 3.4971 - regression_loss: 2.2232 - classification_loss: 1.2740\n",
      "  28/2300 [..............................] - ETA: 4:30:01 - loss: 3.4911 - regression_loss: 2.2189 - classification_loss: 1.2723\n",
      "  29/2300 [..............................] - ETA: 4:29:46 - loss: 3.5113 - regression_loss: 2.2413 - classification_loss: 1.2700\n",
      "  30/2300 [..............................] - ETA: 4:29:22 - loss: 3.5046 - regression_loss: 2.2363 - classification_loss: 1.2683\n",
      "  31/2300 [..............................] - ETA: 4:28:41 - loss: 3.4770 - regression_loss: 2.2080 - classification_loss: 1.2689\n",
      "  32/2300 [..............................] - ETA: 4:27:48 - loss: 3.4879 - regression_loss: 2.2207 - classification_loss: 1.2672\n",
      "  33/2300 [..............................] - ETA: 4:27:03 - loss: 3.4848 - regression_loss: 2.2185 - classification_loss: 1.2664\n",
      "  34/2300 [..............................] - ETA: 4:28:11 - loss: 3.4914 - regression_loss: 2.2274 - classification_loss: 1.2640\n",
      "  35/2300 [..............................] - ETA: 4:27:29 - loss: 3.4604 - regression_loss: 2.1932 - classification_loss: 1.2671\n",
      "  36/2300 [..............................] - ETA: 4:26:43 - loss: 3.4647 - regression_loss: 2.1996 - classification_loss: 1.2651\n",
      "  37/2300 [..............................] - ETA: 4:26:37 - loss: 3.4700 - regression_loss: 2.2066 - classification_loss: 1.2634\n",
      "  38/2300 [..............................] - ETA: 4:26:32 - loss: 3.4718 - regression_loss: 2.2094 - classification_loss: 1.2624\n",
      "  39/2300 [..............................] - ETA: 4:26:21 - loss: 3.4604 - regression_loss: 2.1985 - classification_loss: 1.2619\n",
      "  40/2300 [..............................] - ETA: 4:27:00 - loss: 3.4517 - regression_loss: 2.1916 - classification_loss: 1.2602\n",
      "  41/2300 [..............................] - ETA: 4:26:13 - loss: 3.4610 - regression_loss: 2.2019 - classification_loss: 1.2591\n",
      "  42/2300 [..............................] - ETA: 4:25:34 - loss: 3.4537 - regression_loss: 2.1962 - classification_loss: 1.2575\n",
      "  43/2300 [..............................] - ETA: 4:24:55 - loss: 3.4568 - regression_loss: 2.2004 - classification_loss: 1.2564\n",
      "  44/2300 [..............................] - ETA: 4:24:54 - loss: 3.4643 - regression_loss: 2.2093 - classification_loss: 1.2550\n",
      "  45/2300 [..............................] - ETA: 4:24:21 - loss: 3.4602 - regression_loss: 2.2062 - classification_loss: 1.2540\n",
      "  46/2300 [..............................] - ETA: 4:23:46 - loss: 3.4671 - regression_loss: 2.2142 - classification_loss: 1.2529\n",
      "  47/2300 [..............................] - ETA: 4:23:11 - loss: 3.4846 - regression_loss: 2.2320 - classification_loss: 1.2526\n",
      "  48/2300 [..............................] - ETA: 4:23:42 - loss: 3.4778 - regression_loss: 2.2263 - classification_loss: 1.2515\n",
      "  49/2300 [..............................] - ETA: 4:24:14 - loss: 3.4682 - regression_loss: 2.2171 - classification_loss: 1.2510\n",
      "  50/2300 [..............................] - ETA: 4:24:09 - loss: 3.4546 - regression_loss: 2.2043 - classification_loss: 1.2502\n",
      "  51/2300 [..............................] - ETA: 4:25:16 - loss: 3.4600 - regression_loss: 2.2092 - classification_loss: 1.2508\n",
      "  52/2300 [..............................] - ETA: 4:24:48 - loss: 3.4711 - regression_loss: 2.2207 - classification_loss: 1.2504\n",
      "  53/2300 [..............................] - ETA: 4:25:25 - loss: 3.4815 - regression_loss: 2.2291 - classification_loss: 1.2524\n",
      "  54/2300 [..............................] - ETA: 4:24:57 - loss: 3.4822 - regression_loss: 2.2298 - classification_loss: 1.2524\n",
      "  55/2300 [..............................] - ETA: 4:24:32 - loss: 3.4847 - regression_loss: 2.2334 - classification_loss: 1.2512\n",
      "  56/2300 [..............................] - ETA: 4:24:43 - loss: 3.4600 - regression_loss: 2.2072 - classification_loss: 1.2528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  57/2300 [..............................] - ETA: 4:24:27 - loss: 3.4542 - regression_loss: 2.2025 - classification_loss: 1.2517\n",
      "  58/2300 [..............................] - ETA: 4:24:51 - loss: 3.4378 - regression_loss: 2.1837 - classification_loss: 1.2542\n",
      "  59/2300 [..............................] - ETA: 4:24:21 - loss: 3.4412 - regression_loss: 2.1875 - classification_loss: 1.2537\n",
      "  60/2300 [..............................] - ETA: 4:23:49 - loss: 3.4443 - regression_loss: 2.1913 - classification_loss: 1.2530\n",
      "  61/2300 [..............................] - ETA: 4:24:09 - loss: 3.4436 - regression_loss: 2.1918 - classification_loss: 1.2518\n",
      "  62/2300 [..............................] - ETA: 4:24:27 - loss: 3.4422 - regression_loss: 2.1914 - classification_loss: 1.2508\n",
      "  63/2300 [..............................] - ETA: 4:23:55 - loss: 3.4496 - regression_loss: 2.1997 - classification_loss: 1.2499\n",
      "  64/2300 [..............................] - ETA: 4:24:17 - loss: 3.4489 - regression_loss: 2.2001 - classification_loss: 1.2488\n",
      "  65/2300 [..............................] - ETA: 4:23:49 - loss: 3.4484 - regression_loss: 2.2004 - classification_loss: 1.2480\n",
      "  66/2300 [..............................] - ETA: 4:23:21 - loss: 3.4431 - regression_loss: 2.1957 - classification_loss: 1.2473\n",
      "  67/2300 [..............................] - ETA: 4:23:54 - loss: 3.4410 - regression_loss: 2.1941 - classification_loss: 1.2469\n",
      "  68/2300 [..............................] - ETA: 4:23:23 - loss: 3.4324 - regression_loss: 2.1847 - classification_loss: 1.2477\n",
      "  69/2300 [..............................] - ETA: 4:23:00 - loss: 3.4212 - regression_loss: 2.1737 - classification_loss: 1.2474\n",
      "  70/2300 [..............................] - ETA: 4:22:31 - loss: 3.4257 - regression_loss: 2.1788 - classification_loss: 1.2469\n"
     ]
    }
   ],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "UMA1_eZKxb0_",
    "Y1g_gkgoNR8a"
   ],
   "name": "RetinaNet_self_train.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
